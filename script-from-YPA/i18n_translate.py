#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import json
import os
import pathlib
import re
from dataclasses import dataclass, asdict
from typing import Dict, List, Tuple

try:
    # å®˜æ–¹ Python SDKï¼šfrom openai import OpenAIï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEY
    from openai import OpenAI
except ImportError:
    OpenAI = None

# åŒ¹é…ä¸­æ—¥éŸ©å­—ç¬¦ï¼šä¸­æ—¥éŸ©ç»Ÿä¸€è¡¨æ„æ–‡å­— + å¹³å‡å + ç‰‡å‡å
CJK_RE = re.compile(r"[\u3400-\u4dbf\u4e00-\u9fff\u3040-\u30ff]+")

# è¦æ‰«æçš„æ–‡ä»¶åç¼€ï¼ˆæŒ‰éœ€å¢åˆ ï¼‰
INCLUDE_EXT = {".php", ".html", ".htm", ".js", ".ts", ".vue"}

# ä¸è¿›å…¥çš„ç›®å½•ï¼ˆæŒ‰ä½ é¡¹ç›®æƒ…å†µå¯ä»¥è°ƒæ•´ï¼‰
EXCLUDE_DIRS = {
    ".git",
    "vendor",
    "runtime",
    "storage",
    "node_modules",
    "dist",
    "build",
    "public/dist",
}


@dataclass
class Occurrence:
    file: str   # ç›¸å¯¹é¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
    line: int   # è¡Œå·ï¼ˆ1 å¼€å§‹ï¼‰
    context: str  # å½“å‰æ•´è¡Œæ–‡æœ¬ï¼Œç”¨äºç¿»è¯‘å‚è€ƒ


@dataclass
class Phrase:
    id: int
    text: str
    occurrences: List[Occurrence]


# ============== scanï¼šæ‰«æé¡¹ç›®ï¼Œç”Ÿæˆ JSONï¼ˆä½ å·²ç»è·‘è¿‡ï¼Œå¯ä»¥è·³è¿‡ï¼‰ ==============

def scan_project(root: pathlib.Path) -> List[Phrase]:
    """
    æ‰«æé¡¹ç›®ï¼ŒæŒ‰â€œçŸ­è¯­å»é‡ + è®°å½•æ‰€æœ‰å‡ºç°ä½ç½®â€ã€‚
    """
    phrases: Dict[str, Phrase] = {}
    seen_occ = set()
    next_id = 1
    root = root.resolve()

    for dirpath, dirnames, filenames in os.walk(root):
        dirnames[:] = [d for d in dirnames if d not in EXCLUDE_DIRS]

        for filename in filenames:
            ext = pathlib.Path(filename).suffix.lower()
            if ext not in INCLUDE_EXT:
                continue

            path = pathlib.Path(dirpath) / filename
            try:
                text = path.read_text(encoding="utf-8")
            except UnicodeDecodeError:
                # é UTF-8 æ–‡ä»¶ï¼Œç›´æ¥è·³è¿‡
                continue

            rel_path = path.relative_to(root)

            for lineno, line in enumerate(text.splitlines(), start=1):
                if not CJK_RE.search(line):
                    continue

                for m in CJK_RE.finditer(line):
                    phrase_str = m.group(0).strip()
                    if not phrase_str:
                        continue

                    key = (phrase_str, str(rel_path), lineno)
                    if key in seen_occ:
                        continue
                    seen_occ.add(key)

                    if phrase_str not in phrases:
                        phrases[phrase_str] = Phrase(
                            id=next_id,
                            text=phrase_str,
                            occurrences=[],
                        )
                        next_id += 1

                    phrases[phrase_str].occurrences.append(
                        Occurrence(
                            file=str(rel_path).replace("\\", "/"),
                            line=lineno,
                            context=line.rstrip("\n"),
                        )
                    )

    return list(phrases.values())


def cmd_scan(args):
    root = pathlib.Path(args.root)
    phrases = scan_project(root)

    items = []
    for p in sorted(phrases, key=lambda x: x.id):
        d = asdict(p)
        d["translated"] = None  # é¢„ç•™ç¿»è¯‘å­—æ®µ
        items.append(d)

    out_obj = {"items": items}
    out_path = pathlib.Path(args.out)
    out_path.write_text(
        json.dumps(out_obj, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    print(f"æ‰«æå®Œæˆï¼Œå‘ç° {len(items)} ä¸ªå”¯ä¸€çŸ­è¯­ï¼Œå·²å†™å…¥ {out_path}")


# ============== translateï¼šç”¨ OpenAI æ‰¹é‡ç¿»è¯‘ JSON ä¸­çš„çŸ­è¯­ ==============

def _load_items(path: pathlib.Path):
    """
    å…¼å®¹ä¸¤ç§ç»“æ„ï¼š
    1) {"items": [...]}
    2) [ ... ]
    """
    data = json.loads(path.read_text(encoding="utf-8"))
    if isinstance(data, dict) and "items" in data:
        items = data["items"]
    elif isinstance(data, list):
        items = data
    else:
        raise SystemExit("JSON æ ¼å¼ä¸æ­£ç¡®ï¼Œå¿…é¡»æ˜¯ {\"items\": [...]} æˆ–çº¯æ•°ç»„")
    return items, data


def call_openai_batch(client, batch, src_lang, tgt_lang, model):
    """
    æ‰¹é‡ç¿»è¯‘ä¸€ç»„çŸ­è¯­ã€‚
    batch: list[dict]ï¼Œæ¥è‡ª JSON é‡Œçš„ itemsï¼Œæ¯ä¸ªè‡³å°‘åŒ…å« id, text, occurrencesã€‚
    è¿”å›: {id: translated_text}
    """
    import time
    import json

    payload = []
    for item in batch:
        occs = item.get("occurrences") or []
        context = ""
        file = ""

        if occs:
            context = occs[0].get("context", "") or ""
            file = occs[0].get("file", "") or ""

            # ğŸ”¥ å…³é”®ï¼šæˆªæ–­è¿‡é•¿ contextï¼Œé¿å…æŸäº›ä¸€è¡Œå‡ ä¸‡å­—ç¬¦æŠŠä¸Šä¸‹æ–‡æ’‘çˆ†
            max_ctx_len = 200  # ä½ å¯ä»¥æŒ‰éœ€è°ƒï¼Œæ¯”å¦‚ 200/300
            if len(context) > max_ctx_len:
                phrase = item.get("text", "") or ""
                pos = context.find(phrase) if phrase else -1
                if pos != -1:
                    # å°è¯•ä¿ç•™çŸ­è¯­é™„è¿‘çš„ä¸€å°æ®µä¸Šä¸‹æ–‡
                    start = max(0, pos - 60)
                    end = min(len(context), pos + len(phrase) + 60)
                    context = context[start:end]
                else:
                    # æ‰¾ä¸åˆ°å°±ç®€å•æˆªå‰ 200 å­—ç¬¦
                    context = context[:max_ctx_len]

        payload.append(
            {
                "id": item["id"],
                "text": item["text"],
                "context": context,
                "file": file,
            }
        )

    system_prompt = (
        "You are a professional software localization translator. "
        "Translate UI strings for a web application."
    )

    user_prompt = (
        f"è¯·æŠŠä¸‹é¢ JSON æ•°ç»„é‡Œçš„ text å­—æ®µä»{src_lang}ç¿»è¯‘æˆ{tgt_lang}ã€‚\n"
        "è¦æ±‚ï¼š\n"
        "1. ä¸¥æ ¼ä¿ç•™å˜é‡åã€å ä½ç¬¦å’Œæ ¼å¼ï¼Œä¾‹å¦‚ {name}ã€{0}ã€%sã€%dã€%1$s ç­‰ï¼Œä¸èƒ½æ”¹åŠ¨ã€‚\n"
        "2. ä¸¥æ ¼ä¿ç•™ HTML æ ‡ç­¾å’Œå±æ€§ï¼Œåªç¿»è¯‘æ ‡ç­¾å†…ç”¨æˆ·å¯è§çš„æ–‡å­—ã€‚\n"
        "3. å‚è€ƒ context å’Œ file åˆ¤æ–­è¯­å¢ƒï¼Œä½¿ç¿»è¯‘é€‚åˆç½‘ç«™/åå°ç®¡ç†çš„ UI æ–‡æ¡ˆã€‚\n"
        "4. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Šã€‚\n"
        "5. åªè¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œç»“æ„ä¸¥æ ¼ä¸ºï¼š\n"
        '   { \"items\": [ {\"id\": 1, \"translated\": \"...\"}, ... ] }\n\n'
        f"ä¸‹é¢æ˜¯å¾…ç¿»è¯‘æ•°ç»„ï¼š\n"
        f"{json.dumps(payload, ensure_ascii=False)}"
    )

    # ç”¨ Responses APIï¼Œå¹¶ç”¨ text.format è¦æ±‚è¿”å› JSON å¯¹è±¡
    resp = client.responses.create(
        model=model,
        input=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        text={
            "format": {
                "type": "json_object"
            }
        },
    )

    raw = resp.output_text  # SDK ä¼šæŠŠæ‰€æœ‰æ–‡æœ¬è¾“å‡ºæ‹¼åˆ°è¿™é‡Œ

    try:
        obj = json.loads(raw)
    except json.JSONDecodeError:
        raise RuntimeError(f"æ¨¡å‹è¿”å›çš„ä¸æ˜¯åˆæ³• JSONï¼š\n{raw}")

    items = obj.get("items", [])
    mapping: Dict[int, str] = {}
    for it in items:
        mapping[int(it["id"])] = it["translated"]

    # ç®€å•é™é€Ÿï¼Œé˜²ä¸€æ‰‹ QPS è¿‡é«˜ï¼ˆä½ ä¹Ÿå¯ä»¥å…³æ‰ï¼‰
    time.sleep(0.3)
    return mapping



def cmd_translate(args):
    if OpenAI is None:
        raise SystemExit("è¯·å…ˆ `pip install openai` å†è¿è¡Œ translate å‘½ä»¤ã€‚")

    import json
    import time
    from pathlib import Path

    client = OpenAI()  # ä½¿ç”¨ç¯å¢ƒå˜é‡ OPENAI_API_KEY
    src_lang = args.src
    tgt_lang = args.tgt
    model = args.model
    batch_size = args.batch
    sleep_sec = getattr(args, "sleep", 0.2)

    input_path = Path(args.input)
    out_path = Path(args.out)

    # å…¼å®¹ä¸¤ç§ç»“æ„ï¼š{"items": [...]} æˆ–çº¯æ•°ç»„ [...]
    raw = input_path.read_text(encoding="utf-8")
    data = json.loads(raw)
    if isinstance(data, dict) and "items" in data:
        items = data["items"]
        container = data  # ç”¨äºåé¢å†™ meta
    elif isinstance(data, list):
        items = data
        container = None
    else:
        raise SystemExit("JSON æ ¼å¼ä¸æ­£ç¡®ï¼Œå¿…é¡»æ˜¯ {\"items\": [...]} æˆ–çº¯æ•°ç»„")

    # åªç¿»è¯‘è¿˜æ²¡æœ‰ translated çš„æ¡ç›®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­è·‘ï¼‰
    to_translate = [it for it in items if not it.get("translated")]
    total = len(to_translate)
    if total == 0:
        print("æ‰€æœ‰æ¡ç›®çš„ translated å­—æ®µéƒ½å·²å­˜åœ¨ï¼Œä¸éœ€è¦ç¿»è¯‘ã€‚")
        return

    print(f"å…±æœ‰ {total} æ¡éœ€è¦ç¿»è¯‘ï¼Œå°†åˆ†æ‰¹è°ƒç”¨ OpenAI æ¨¡å‹ {model} ...")

    def save_progress():
        """æ¯ä¸€æ‰¹ç¿»å®Œå†™ä¸€æ¬¡ JSONï¼Œé˜²æ­¢ä¸­é€”æŒ‚æ‰ä¸¢è¿›åº¦ã€‚"""
        if container is not None:
            container["items"] = items
            meta = container.setdefault("meta", {})
            meta["src_lang"] = src_lang
            meta["tgt_lang"] = tgt_lang
            meta["model"] = model
            meta["translated_count"] = sum(1 for it in items if it.get("translated"))
            out_obj = container
        else:
            out_obj = items

        out_path.write_text(
            json.dumps(out_obj, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        print(f"  [å·²ä¿å­˜è¿›åº¦åˆ° {out_path}]")

    # æŒ‰ batch åˆ†æ‰¹è°ƒç”¨
    for i in range(0, total, batch_size):
        batch = to_translate[i: i + batch_size]
        print(f"  -> ç¿»è¯‘ç¬¬ {i + 1} ~ {i + len(batch)} æ¡...")

        mapping = call_openai_batch(client, batch, src_lang, tgt_lang, model)

        # å†™å›åˆ° itemsï¼ˆbatch é‡Œçš„ dict æœ¬èº«å°±æ˜¯ items çš„å¼•ç”¨ï¼‰
        for item in batch:
            _id = int(item["id"])
            if _id in mapping:
                item["translated"] = mapping[_id]

        save_progress()
        time.sleep(sleep_sec)

    print("å…¨éƒ¨ç¿»è¯‘å®Œæˆã€‚")


# ============== applyï¼šæŒ‰ file+line ç²¾ç¡®å›å†™åˆ°æºç  ==============

def cmd_apply(args):
    root = pathlib.Path(args.root).resolve()
    mapping_path = pathlib.Path(args.mapping)

    items, _ = _load_items(mapping_path)

    # æ„å»ºï¼šfile -> line -> [(src, tgt), ...]
    file_line_map: Dict[str, Dict[int, List[Tuple[str, str]]]] = {}

    for row in items:
        text = row["text"]
        translated = row.get("translated")
        if not translated:
            continue

        occs = row.get("occurrences") or []
        for occ in occs:
            file = occ["file"]
            line = int(occ["line"])
            file_dict = file_line_map.setdefault(file, {})
            line_list = file_dict.setdefault(line, [])
            line_list.append((text, translated))

    if not file_line_map:
        print("æ²¡æœ‰ä»»ä½• translated å­—æ®µï¼Œapply ä¸ä¼šåšä¿®æ”¹ã€‚")
        return

    for rel_file, line_map in file_line_map.items():
        path = (root / rel_file).resolve()
        if not path.exists():
            print(f"[è­¦å‘Š] æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ï¼š{rel_file}")
            continue

        try:
            content = path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            print(f"[è­¦å‘Š] æ–‡ä»¶ä¸æ˜¯ UTF-8 ç¼–ç ï¼Œè·³è¿‡ï¼š{rel_file}")
            continue

        lines = content.splitlines(keepends=True)
        changed = False

        for line_no, repl_list in line_map.items():
            idx = line_no - 1
            if idx < 0 or idx >= len(lines):
                print(f"[è­¦å‘Š] è¡Œå·è¶…å‡ºèŒƒå›´ï¼š{rel_file}:{line_no}")
                continue

            line_text = lines[idx]
            original_line = line_text

            # åŒä¸€è¡Œå¯èƒ½æœ‰å¤šä¸ªçŸ­è¯­ï¼Œé€ä¸ªæ›¿æ¢
            for src, tgt in repl_list:
                line_text = line_text.replace(src, tgt)

            if line_text != original_line:
                lines[idx] = line_text
                changed = True

        if changed:
            new_content = "".join(lines)
            backup = path.with_suffix(path.suffix + ".bak")
            if not backup.exists():
                backup.write_text(content, encoding="utf-8")
                print(f"å·²ç”Ÿæˆå¤‡ä»½ï¼š{backup}")
            path.write_text(new_content, encoding="utf-8")
            print(f"å·²åº”ç”¨ç¿»è¯‘ï¼š{rel_file}")
        else:
            print(f"æœªä¿®æ”¹ï¼š{rel_file}")


# ============== CLI å…¥å£ ==============

def main():
    parser = argparse.ArgumentParser(description="æ‰«æ/ç¿»è¯‘/å›å†™é¡¹ç›®ä¸­çš„ä¸­æ—¥éŸ©æ–‡æœ¬")
    sub = parser.add_subparsers(dest="cmd", required=True)

    # scanï¼ˆä½ å·²ç»è·‘è¿‡äº†ï¼Œå¯ä»¥å¿½ç•¥ï¼‰
    p_scan = sub.add_parser("scan", help="æ‰«æé¡¹ç›®ï¼Œç”Ÿæˆå¾…ç¿»è¯‘ JSON")
    p_scan.add_argument("--root", default=".", help="é¡¹ç›®æ ¹ç›®å½•")
    p_scan.add_argument("--out", default="translations.todo.json", help="è¾“å‡º JSON æ–‡ä»¶")
    p_scan.set_defaults(func=cmd_scan)

    # translateï¼šç”¨ OpenAI æ‰¹é‡ç¿»è¯‘
    p_trans = sub.add_parser("translate", help="è°ƒç”¨ OpenAI API æ‰¹é‡ç¿»è¯‘ JSON ä¸­çš„çŸ­è¯­")
    p_trans.add_argument("--input", required=True, help="scan ç”Ÿæˆçš„ JSON æ–‡ä»¶è·¯å¾„")
    p_trans.add_argument(
        "--out",
        default="translations.done.json",
        help="ç¿»è¯‘åè¾“å‡º JSON æ–‡ä»¶è·¯å¾„",
    )
    p_trans.add_argument(
        "--src",
        default="æ—¥æ–‡",
        help="æºè¯­è¨€æè¿°ï¼ˆç”¨äº promptï¼Œä¾‹å¦‚ï¼šæ—¥æ–‡ / ç®€ä½“ä¸­æ–‡ / ç¹ä½“ä¸­æ–‡ / è‹±æ–‡ï¼‰",
    )
    p_trans.add_argument(
        "--tgt",
        default="ç®€ä½“ä¸­æ–‡",
        help="ç›®æ ‡è¯­è¨€æè¿°ï¼ˆç”¨äº promptï¼‰",
    )
    p_trans.add_argument(
        "--model",
        default="gpt-5.1",
        help="æ¨¡å‹åç§°ï¼ˆå¦‚ gpt-4.1-mini, gpt-4.1 ç­‰ï¼‰",
    )
    p_trans.add_argument(
        "--batch",
        type=int,
        default=50,
        help="æ¯æ¬¡è¯·æ±‚ç¿»è¯‘å¤šå°‘æ¡ï¼ˆå¯ä»¥æ ¹æ® token æƒ…å†µè°ƒå¤§/è°ƒå°ï¼‰",
    )
    p_trans.add_argument(
        "--sleep",
        type=float,
        default=0.2,
        help="ä¸¤æ¬¡è¯·æ±‚ä¹‹é—´ sleep ç§’æ•°ï¼Œé˜²æ­¢è¿‡å¿«è§¦å‘é™é€Ÿ",
    )
    p_trans.set_defaults(func=cmd_translate)

    # applyï¼šå›å†™åˆ°æºç 
    p_apply = sub.add_parser("apply", help="æ ¹æ® JSON mapping å›å†™ç¿»è¯‘ç»“æœåˆ°æºç æ–‡ä»¶")
    p_apply.add_argument(
        "--root",
        default=".",
        help="é¡¹ç›®æ ¹ç›®å½•ï¼ˆä¸ scan æ—¶ä¿æŒä¸€è‡´ï¼‰",
    )
    p_apply.add_argument(
        "--mapping",
        required=True,
        help="translate ç”Ÿæˆçš„ JSON æ–‡ä»¶è·¯å¾„",
    )
    p_apply.set_defaults(func=cmd_apply)

    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()
